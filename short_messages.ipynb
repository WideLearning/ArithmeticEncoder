{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install peft accelerate loralib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from peft import PeftConfig, PeftModel\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    integrations,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Using custom data configuration default-c026a0da68931db6\n",
      "Found cached dataset text (/home/mike/.cache/huggingface/datasets/text/default-c026a0da68931db6/0.0.0)\n",
      "Loading cached processed dataset at /home/mike/.cache/huggingface/datasets/text/default-c026a0da68931db6/0.0.0/cache-4c558e740f1d48fa.arrow\n"
     ]
    }
   ],
   "source": [
    "base_name = \"ai-forever/rugpt3small_based_on_gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(base_name)\n",
    "\n",
    "full_dataset = Dataset.from_text(\"spam_messages_names.txt\")\n",
    "full_dataset = full_dataset.map(\n",
    "    lambda example: tokenizer(example[\"text\"]), batched=True\n",
    ")\n",
    "data_dict = full_dataset.train_test_split(test_size=0.01, shuffle=True, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61057 617\n",
      "{'text': 'Sōl Astrī: Не похоже', 'input_ids': [55, 134, 240, 80, 49062, 86, 133, 109, 30, 832, 5175], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "430\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(data_dict[\"train\"]), len(data_dict[\"test\"]))\n",
    "print(full_dataset[-1])\n",
    "lengths = np.array(sorted([len(elem[\"input_ids\"]) for elem in full_dataset]))\n",
    "print(lengths[-1])\n",
    "\n",
    "plt.plot(lengths)\n",
    "plt.ylim(0, 80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # freeze the model - train adapters later\n",
    "    if param.ndim == 1:\n",
    "        # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
    "        param.data = param.data.to(torch.float32)\n",
    "\n",
    "model.gradient_checkpointing_enable()  # reduce number of stored activations\n",
    "\n",
    "\n",
    "class CastOutputToFloat(nn.Sequential):\n",
    "    def forward(self, x):\n",
    "        return super().forward(x).to(torch.float32)\n",
    "\n",
    "\n",
    "model.lm_head = CastOutputToFloat(model.lm_head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/.local/lib/python3.10/site-packages/peft/tuners/lora.py:240: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 589824 || all params: 125821440 || trainable: 0.47%\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable: {100 * trainable_params / all_param:.2f}%\"\n",
    "    )\n",
    "\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,  # attention heads\n",
    "    lora_alpha=32,  # alpha scaling\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",  # set this for CLM or Seq2Seq\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=100,\n",
    "    max_steps=200,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=1,\n",
    "    output_dir=\"outputs\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    train_dataset=data_dict[\"train\"],\n",
    "    eval_dataset=data_dict[\"test\"],\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 617\n",
      "  Batch size = 8\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b65c9507c94b9a8386d6272d221a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_before = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.105103492736816, 'eval_runtime': 31.114, 'eval_samples_per_second': 19.83, 'eval_steps_per_second': 2.507}\n",
      "Results for a \n",
      "a  \n",
      "\n",
      "\n",
      "13410664\tevstoliya-3\t2018-01-\n",
      "a  - http://specialtyaz.ru...✂ \n",
      " [url=http://spec\n",
      "a  \n",
      "\t\tИ всё идёт как надо. \n",
      "\t\tА всё идёт, как по плану.\n",
      "a ugly\" for me\n",
      "\n",
      "The Wizards of the Witcher 3 (1937\n",
      "a  &amp;lt;!-- IRE.END, SHEARER.\n",
      "a ubereait, poderia pacera, et los datos\n",
      "a é traviada e melhor seja é, comentário p\n",
      "a },      {1},      {2},      {3},\n",
      "a echo \\[################\n",
      "a ua, pelicanos ou fácil, do eu sacriir\n",
      "Results for Mikhail Budnikov:\n",
      "Mikhail Budnikov: \"Cross-continental\" - это только мое субъективное мнение. И я искренне не\n",
      "Mikhail Budnikov: The new #ModulationBridge can be called a model for “Portal” techn\n",
      "Mikhail Budnikov: \"Все что сегодня происходит в нашей стране сегодня, в том числе наши действия, – это отражение нашей\n",
      "Mikhail Budnikov: «Полукоммерческая недвижимость в г. Москве», Москва, «Территория недвижимости и\n",
      "Mikhail Budnikov: Что значит \"Бороться и искать\" на практике? - \"Бороться и искать\" - это\n",
      "Mikhail Budnikov: «В связи с закрытием сезона в городе не будет туристов». Я знаю, что в этом сезоне\n",
      "Mikhail Budnikov: «Мы знаем, зачем мы живем, понимаем, как важно для нас сохранять традиции. Потому что люди\n",
      "Mikhail Budnikov:\n",
      "\n",
      "Seminars can be expressed in\n",
      "\n",
      "\n",
      "North Carolina F.C\n",
      "Mikhail Budnikov: \"В стране должна быть четкая гражданская позиция как и в обществе, так и между людьми\". \n",
      "Mikhail Budnikov:\n",
      "\"In February 2015, a young journalist named Inspector Loritz, with a\n",
      "Results for Rodion Khvorostov:\n",
      "Rodion Khvorostov: &laquo;Борис Годунов - это фигура очень важная в политической деятельности, но никак\n",
      "Rodion Khvorostov: \"Ситуация здесь – это не Крымская весна, это не референдум.  Это не та ситуация\n",
      "Rodion Khvorostov: \"В чем суть акции, которая проводилась среди сторонников Виктора Януковича.  По сути, была попытка дестабили\n",
      "Rodion Khvorostov:  Валерий Карпков -  «…Валерий Карпков -\n",
      "Rodion Khvorostov: Не надо ни за что винить ни граждан Российской Федерации, ни всех кто там живет.&nbsp;\n",
      "Rodion Khvorostov: \"Белорусская Республика на пути интеграции с Белоруссией – это уже не просто одно государство, а\n",
      "Rodion Khvorostov: «На протяжении всех лет моя Родина не была и у меня нет Родины и в дальнейшем».\n",
      "\n",
      "\n",
      "Rodion Khvorostov: «В данном случае мы имеем дело с явной критикой руководства, которое в настоящее время занимается только\n",
      "Rodion Khvorostov: \"Донецкая народная республика уже не нужна никому.  Они уже ничего не смогут сделать, просто\n",
      "Rodion Khvorostov: \"Чеченовскому войску нужна помощь из Москвы: они не хотят работать на Кремль!\"\n",
      "Results for Veronika Sirotkina:\n",
      "Veronika Sirotkina: О любви и о себе \n",
      "Анна Герман-Россет Remarine Travelling:\n",
      "Veronika Sirotkina: \"Я не могла представить себя со старыми фотками. Не могу представить себя со старыми фотографиями на фоне\n",
      "Veronika Sirotkina: \"Берегите себя, ваши дети - всегда дети...\"  Если вы хотите сохранить свою индивидуальность\n",
      "Veronika Sirotkina: \"Это — только начало\" \n",
      " Елена ПАНГЕЛЬ, директор сети ресторанов \"Марс\":\n",
      "Veronika Sirotkina: \"Как же все таки в жизни не везет с мужчинами\" \n",
      " Екатерина: \"... и вообще, в\n",
      "Veronika Sirotkina: «Опираясь на себя, я делаю шаги вперед». - «Я все еще занимаюсь медитацией\n",
      "Veronika Sirotkina: «Если на Западе вас воспринимают как женщину, то у нас женщин не воспринимают как мужчин». В статье\n",
      "Veronika Sirotkina: http://www.youtube.com/watch?v=MJUlC4\n",
      "Veronika Sirotkina: \"I love to have a single person!\" Posted by Роман Савельев on&nbsp;8\n",
      "Veronika Sirotkina: https://t.co/FZljIObCmJ https://t.\n"
     ]
    }
   ],
   "source": [
    "print(results_before)\n",
    "for prompt in [\"a \", \"Mikhail Budnikov:\", \"Rodion Khvorostov:\", \"Veronika Sirotkina:\"]:\n",
    "    print(\"Results for\", prompt)\n",
    "    for it in range(10):\n",
    "        tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        g = model.generate(**tokens, max_new_tokens=20, pad_token_id=50256, return_dict_in_generate=True, do_sample=True)\n",
    "        prediction = g.sequences[0]\n",
    "        print(tokenizer.decode(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "/home/mike/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 61057\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 200\n",
      "  Number of trainable parameters = 125231616\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8f25d880f94c4fb220a36e5af061a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2611, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}\n",
      "{'loss': 5.2101, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.0}\n",
      "{'loss': 5.4502, 'learning_rate': 6e-06, 'epoch': 0.0}\n",
      "{'loss': 4.8848, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.0}\n",
      "{'loss': 5.2576, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 4.8429, 'learning_rate': 1.2e-05, 'epoch': 0.0}\n",
      "{'loss': 4.674, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.0}\n",
      "{'loss': 4.761, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.0}\n",
      "{'loss': 4.7102, 'learning_rate': 1.8e-05, 'epoch': 0.0}\n",
      "{'loss': 4.352, 'learning_rate': 2e-05, 'epoch': 0.0}\n",
      "{'loss': 3.7165, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.0}\n",
      "{'loss': 4.0495, 'learning_rate': 2.4e-05, 'epoch': 0.0}\n",
      "{'loss': 3.8335, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.0}\n",
      "{'loss': 3.9267, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6018, 'learning_rate': 3e-05, 'epoch': 0.0}\n",
      "{'loss': 3.8515, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.0}\n",
      "{'loss': 3.9997, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.0}\n",
      "{'loss': 4.0429, 'learning_rate': 3.6e-05, 'epoch': 0.0}\n",
      "{'loss': 3.5947, 'learning_rate': 3.8e-05, 'epoch': 0.0}\n",
      "{'loss': 3.3986, 'learning_rate': 4e-05, 'epoch': 0.01}\n",
      "{'loss': 3.6872, 'learning_rate': 4.2e-05, 'epoch': 0.01}\n",
      "{'loss': 4.0387, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3577, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5157, 'learning_rate': 4.8e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5158, 'learning_rate': 5e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4903, 'learning_rate': 5.2000000000000004e-05, 'epoch': 0.01}\n",
      "{'loss': 3.453, 'learning_rate': 5.4000000000000005e-05, 'epoch': 0.01}\n",
      "{'loss': 3.0734, 'learning_rate': 5.6000000000000006e-05, 'epoch': 0.01}\n",
      "{'loss': 3.7651, 'learning_rate': 5.8e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5858, 'learning_rate': 6e-05, 'epoch': 0.01}\n",
      "{'loss': 3.1225, 'learning_rate': 6.2e-05, 'epoch': 0.01}\n",
      "{'loss': 2.5648, 'learning_rate': 6.400000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 3.1947, 'learning_rate': 6.6e-05, 'epoch': 0.01}\n",
      "{'loss': 2.9097, 'learning_rate': 6.800000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3262, 'learning_rate': 7e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4336, 'learning_rate': 7.2e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3644, 'learning_rate': 7.4e-05, 'epoch': 0.01}\n",
      "{'loss': 2.8017, 'learning_rate': 7.6e-05, 'epoch': 0.01}\n",
      "{'loss': 2.8468, 'learning_rate': 7.800000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 3.1059, 'learning_rate': 8e-05, 'epoch': 0.01}\n",
      "{'loss': 3.1536, 'learning_rate': 8.2e-05, 'epoch': 0.01}\n",
      "{'loss': 3.7747, 'learning_rate': 8.4e-05, 'epoch': 0.01}\n",
      "{'loss': 2.7421, 'learning_rate': 8.6e-05, 'epoch': 0.01}\n",
      "{'loss': 3.0506, 'learning_rate': 8.800000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 3.2802, 'learning_rate': 9e-05, 'epoch': 0.01}\n",
      "{'loss': 2.9085, 'learning_rate': 9.200000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 2.6063, 'learning_rate': 9.4e-05, 'epoch': 0.01}\n",
      "{'loss': 2.4029, 'learning_rate': 9.6e-05, 'epoch': 0.01}\n",
      "{'loss': 3.431, 'learning_rate': 9.8e-05, 'epoch': 0.01}\n",
      "{'loss': 3.0594, 'learning_rate': 0.0001, 'epoch': 0.01}\n",
      "{'loss': 3.0178, 'learning_rate': 0.00010200000000000001, 'epoch': 0.01}\n",
      "{'loss': 3.0033, 'learning_rate': 0.00010400000000000001, 'epoch': 0.01}\n",
      "{'loss': 2.7714, 'learning_rate': 0.00010600000000000002, 'epoch': 0.01}\n",
      "{'loss': 2.9727, 'learning_rate': 0.00010800000000000001, 'epoch': 0.01}\n",
      "{'loss': 2.8277, 'learning_rate': 0.00011000000000000002, 'epoch': 0.01}\n",
      "{'loss': 2.8877, 'learning_rate': 0.00011200000000000001, 'epoch': 0.01}\n",
      "{'loss': 2.5782, 'learning_rate': 0.00011399999999999999, 'epoch': 0.01}\n",
      "{'loss': 3.1792, 'learning_rate': 0.000116, 'epoch': 0.02}\n",
      "{'loss': 2.8416, 'learning_rate': 0.000118, 'epoch': 0.02}\n",
      "{'loss': 3.3715, 'learning_rate': 0.00012, 'epoch': 0.02}\n",
      "{'loss': 2.2283, 'learning_rate': 0.000122, 'epoch': 0.02}\n",
      "{'loss': 2.8636, 'learning_rate': 0.000124, 'epoch': 0.02}\n",
      "{'loss': 2.6885, 'learning_rate': 0.000126, 'epoch': 0.02}\n",
      "{'loss': 2.4856, 'learning_rate': 0.00012800000000000002, 'epoch': 0.02}\n",
      "{'loss': 2.9015, 'learning_rate': 0.00013000000000000002, 'epoch': 0.02}\n",
      "{'loss': 2.9287, 'learning_rate': 0.000132, 'epoch': 0.02}\n",
      "{'loss': 2.9259, 'learning_rate': 0.000134, 'epoch': 0.02}\n",
      "{'loss': 3.332, 'learning_rate': 0.00013600000000000003, 'epoch': 0.02}\n",
      "{'loss': 2.663, 'learning_rate': 0.000138, 'epoch': 0.02}\n",
      "{'loss': 2.2554, 'learning_rate': 0.00014, 'epoch': 0.02}\n",
      "{'loss': 2.764, 'learning_rate': 0.000142, 'epoch': 0.02}\n",
      "{'loss': 2.8123, 'learning_rate': 0.000144, 'epoch': 0.02}\n",
      "{'loss': 2.3443, 'learning_rate': 0.000146, 'epoch': 0.02}\n",
      "{'loss': 3.1575, 'learning_rate': 0.000148, 'epoch': 0.02}\n",
      "{'loss': 2.3818, 'learning_rate': 0.00015000000000000001, 'epoch': 0.02}\n",
      "{'loss': 3.254, 'learning_rate': 0.000152, 'epoch': 0.02}\n",
      "{'loss': 3.3438, 'learning_rate': 0.000154, 'epoch': 0.02}\n",
      "{'loss': 3.3558, 'learning_rate': 0.00015600000000000002, 'epoch': 0.02}\n",
      "{'loss': 3.5347, 'learning_rate': 0.00015800000000000002, 'epoch': 0.02}\n",
      "{'loss': 2.6557, 'learning_rate': 0.00016, 'epoch': 0.02}\n",
      "{'loss': 2.432, 'learning_rate': 0.000162, 'epoch': 0.02}\n",
      "{'loss': 2.9044, 'learning_rate': 0.000164, 'epoch': 0.02}\n",
      "{'loss': 2.7789, 'learning_rate': 0.000166, 'epoch': 0.02}\n",
      "{'loss': 3.1434, 'learning_rate': 0.000168, 'epoch': 0.02}\n",
      "{'loss': 2.6193, 'learning_rate': 0.00017, 'epoch': 0.02}\n",
      "{'loss': 2.6793, 'learning_rate': 0.000172, 'epoch': 0.02}\n",
      "{'loss': 3.0337, 'learning_rate': 0.000174, 'epoch': 0.02}\n",
      "{'loss': 3.3656, 'learning_rate': 0.00017600000000000002, 'epoch': 0.02}\n",
      "{'loss': 2.7994, 'learning_rate': 0.00017800000000000002, 'epoch': 0.02}\n",
      "{'loss': 2.7175, 'learning_rate': 0.00018, 'epoch': 0.02}\n",
      "{'loss': 2.9752, 'learning_rate': 0.000182, 'epoch': 0.02}\n",
      "{'loss': 2.9519, 'learning_rate': 0.00018400000000000003, 'epoch': 0.02}\n",
      "{'loss': 2.9147, 'learning_rate': 0.00018600000000000002, 'epoch': 0.02}\n",
      "{'loss': 2.7844, 'learning_rate': 0.000188, 'epoch': 0.02}\n",
      "{'loss': 2.6005, 'learning_rate': 0.00019, 'epoch': 0.02}\n",
      "{'loss': 3.1435, 'learning_rate': 0.000192, 'epoch': 0.03}\n",
      "{'loss': 2.7807, 'learning_rate': 0.000194, 'epoch': 0.03}\n",
      "{'loss': 3.2598, 'learning_rate': 0.000196, 'epoch': 0.03}\n",
      "{'loss': 2.7014, 'learning_rate': 0.00019800000000000002, 'epoch': 0.03}\n",
      "{'loss': 3.3538, 'learning_rate': 0.0002, 'epoch': 0.03}\n",
      "{'loss': 2.75, 'learning_rate': 0.00019800000000000002, 'epoch': 0.03}\n",
      "{'loss': 2.7722, 'learning_rate': 0.000196, 'epoch': 0.03}\n",
      "{'loss': 3.1169, 'learning_rate': 0.000194, 'epoch': 0.03}\n",
      "{'loss': 3.5856, 'learning_rate': 0.000192, 'epoch': 0.03}\n",
      "{'loss': 3.1359, 'learning_rate': 0.00019, 'epoch': 0.03}\n",
      "{'loss': 3.0166, 'learning_rate': 0.000188, 'epoch': 0.03}\n",
      "{'loss': 2.392, 'learning_rate': 0.00018600000000000002, 'epoch': 0.03}\n",
      "{'loss': 2.6268, 'learning_rate': 0.00018400000000000003, 'epoch': 0.03}\n",
      "{'loss': 2.8368, 'learning_rate': 0.000182, 'epoch': 0.03}\n",
      "{'loss': 3.0379, 'learning_rate': 0.00018, 'epoch': 0.03}\n",
      "{'loss': 3.3577, 'learning_rate': 0.00017800000000000002, 'epoch': 0.03}\n",
      "{'loss': 2.6617, 'learning_rate': 0.00017600000000000002, 'epoch': 0.03}\n",
      "{'loss': 2.5941, 'learning_rate': 0.000174, 'epoch': 0.03}\n",
      "{'loss': 2.6899, 'learning_rate': 0.000172, 'epoch': 0.03}\n",
      "{'loss': 3.1338, 'learning_rate': 0.00017, 'epoch': 0.03}\n",
      "{'loss': 3.5869, 'learning_rate': 0.000168, 'epoch': 0.03}\n",
      "{'loss': 2.8784, 'learning_rate': 0.000166, 'epoch': 0.03}\n",
      "{'loss': 2.6983, 'learning_rate': 0.000164, 'epoch': 0.03}\n",
      "{'loss': 2.055, 'learning_rate': 0.000162, 'epoch': 0.03}\n",
      "{'loss': 2.8445, 'learning_rate': 0.00016, 'epoch': 0.03}\n",
      "{'loss': 2.8942, 'learning_rate': 0.00015800000000000002, 'epoch': 0.03}\n",
      "{'loss': 3.4511, 'learning_rate': 0.00015600000000000002, 'epoch': 0.03}\n",
      "{'loss': 2.8066, 'learning_rate': 0.000154, 'epoch': 0.03}\n",
      "{'loss': 2.5872, 'learning_rate': 0.000152, 'epoch': 0.03}\n",
      "{'loss': 2.6646, 'learning_rate': 0.00015000000000000001, 'epoch': 0.03}\n",
      "{'loss': 3.3017, 'learning_rate': 0.000148, 'epoch': 0.03}\n",
      "{'loss': 3.1523, 'learning_rate': 0.000146, 'epoch': 0.03}\n",
      "{'loss': 2.9117, 'learning_rate': 0.000144, 'epoch': 0.03}\n",
      "{'loss': 2.6159, 'learning_rate': 0.000142, 'epoch': 0.03}\n",
      "{'loss': 2.2596, 'learning_rate': 0.00014, 'epoch': 0.03}\n",
      "{'loss': 3.3191, 'learning_rate': 0.000138, 'epoch': 0.03}\n",
      "{'loss': 2.9402, 'learning_rate': 0.00013600000000000003, 'epoch': 0.03}\n",
      "{'loss': 3.1003, 'learning_rate': 0.000134, 'epoch': 0.03}\n",
      "{'loss': 2.764, 'learning_rate': 0.000132, 'epoch': 0.04}\n",
      "{'loss': 2.8239, 'learning_rate': 0.00013000000000000002, 'epoch': 0.04}\n",
      "{'loss': 3.2727, 'learning_rate': 0.00012800000000000002, 'epoch': 0.04}\n",
      "{'loss': 3.053, 'learning_rate': 0.000126, 'epoch': 0.04}\n",
      "{'loss': 2.4773, 'learning_rate': 0.000124, 'epoch': 0.04}\n",
      "{'loss': 2.7302, 'learning_rate': 0.000122, 'epoch': 0.04}\n",
      "{'loss': 2.3099, 'learning_rate': 0.00012, 'epoch': 0.04}\n",
      "{'loss': 2.6194, 'learning_rate': 0.000118, 'epoch': 0.04}\n",
      "{'loss': 2.82, 'learning_rate': 0.000116, 'epoch': 0.04}\n",
      "{'loss': 2.8273, 'learning_rate': 0.00011399999999999999, 'epoch': 0.04}\n",
      "{'loss': 2.9941, 'learning_rate': 0.00011200000000000001, 'epoch': 0.04}\n",
      "{'loss': 2.9261, 'learning_rate': 0.00011000000000000002, 'epoch': 0.04}\n",
      "{'loss': 2.5039, 'learning_rate': 0.00010800000000000001, 'epoch': 0.04}\n",
      "{'loss': 3.3273, 'learning_rate': 0.00010600000000000002, 'epoch': 0.04}\n",
      "{'loss': 3.1354, 'learning_rate': 0.00010400000000000001, 'epoch': 0.04}\n",
      "{'loss': 2.5864, 'learning_rate': 0.00010200000000000001, 'epoch': 0.04}\n",
      "{'loss': 3.0036, 'learning_rate': 0.0001, 'epoch': 0.04}\n",
      "{'loss': 2.8265, 'learning_rate': 9.8e-05, 'epoch': 0.04}\n",
      "{'loss': 2.7934, 'learning_rate': 9.6e-05, 'epoch': 0.04}\n",
      "{'loss': 3.0288, 'learning_rate': 9.4e-05, 'epoch': 0.04}\n",
      "{'loss': 2.9319, 'learning_rate': 9.200000000000001e-05, 'epoch': 0.04}\n",
      "{'loss': 3.0172, 'learning_rate': 9e-05, 'epoch': 0.04}\n",
      "{'loss': 2.7975, 'learning_rate': 8.800000000000001e-05, 'epoch': 0.04}\n",
      "{'loss': 2.4019, 'learning_rate': 8.6e-05, 'epoch': 0.04}\n",
      "{'loss': 3.0346, 'learning_rate': 8.4e-05, 'epoch': 0.04}\n",
      "{'loss': 2.6622, 'learning_rate': 8.2e-05, 'epoch': 0.04}\n",
      "{'loss': 2.473, 'learning_rate': 8e-05, 'epoch': 0.04}\n",
      "{'loss': 2.4743, 'learning_rate': 7.800000000000001e-05, 'epoch': 0.04}\n",
      "{'loss': 2.8365, 'learning_rate': 7.6e-05, 'epoch': 0.04}\n",
      "{'loss': 2.7194, 'learning_rate': 7.4e-05, 'epoch': 0.04}\n",
      "{'loss': 3.0051, 'learning_rate': 7.2e-05, 'epoch': 0.04}\n",
      "{'loss': 2.8887, 'learning_rate': 7e-05, 'epoch': 0.04}\n",
      "{'loss': 3.132, 'learning_rate': 6.800000000000001e-05, 'epoch': 0.04}\n",
      "{'loss': 2.6443, 'learning_rate': 6.6e-05, 'epoch': 0.04}\n",
      "{'loss': 2.3624, 'learning_rate': 6.400000000000001e-05, 'epoch': 0.04}\n",
      "{'loss': 3.1748, 'learning_rate': 6.2e-05, 'epoch': 0.04}\n",
      "{'loss': 2.566, 'learning_rate': 6e-05, 'epoch': 0.04}\n",
      "{'loss': 2.2749, 'learning_rate': 5.8e-05, 'epoch': 0.04}\n",
      "{'loss': 2.6965, 'learning_rate': 5.6000000000000006e-05, 'epoch': 0.05}\n",
      "{'loss': 2.2937, 'learning_rate': 5.4000000000000005e-05, 'epoch': 0.05}\n",
      "{'loss': 3.1083, 'learning_rate': 5.2000000000000004e-05, 'epoch': 0.05}\n",
      "{'loss': 2.8217, 'learning_rate': 5e-05, 'epoch': 0.05}\n",
      "{'loss': 2.4382, 'learning_rate': 4.8e-05, 'epoch': 0.05}\n",
      "{'loss': 3.0343, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.05}\n",
      "{'loss': 2.6765, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.05}\n",
      "{'loss': 3.1287, 'learning_rate': 4.2e-05, 'epoch': 0.05}\n",
      "{'loss': 2.6334, 'learning_rate': 4e-05, 'epoch': 0.05}\n",
      "{'loss': 2.6446, 'learning_rate': 3.8e-05, 'epoch': 0.05}\n",
      "{'loss': 2.5942, 'learning_rate': 3.6e-05, 'epoch': 0.05}\n",
      "{'loss': 2.7014, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.05}\n",
      "{'loss': 2.5295, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.05}\n",
      "{'loss': 2.7098, 'learning_rate': 3e-05, 'epoch': 0.05}\n",
      "{'loss': 2.3082, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.05}\n",
      "{'loss': 2.2376, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.05}\n",
      "{'loss': 2.2826, 'learning_rate': 2.4e-05, 'epoch': 0.05}\n",
      "{'loss': 3.3359, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.05}\n",
      "{'loss': 2.7153, 'learning_rate': 2e-05, 'epoch': 0.05}\n",
      "{'loss': 2.8917, 'learning_rate': 1.8e-05, 'epoch': 0.05}\n",
      "{'loss': 2.6957, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.05}\n",
      "{'loss': 3.0634, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.05}\n",
      "{'loss': 2.8037, 'learning_rate': 1.2e-05, 'epoch': 0.05}\n",
      "{'loss': 2.1161, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 2.8191, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.05}\n",
      "{'loss': 2.4417, 'learning_rate': 6e-06, 'epoch': 0.05}\n",
      "{'loss': 2.5491, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.05}\n",
      "{'loss': 2.4997, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 617\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1579, 'learning_rate': 0.0, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64acf41220fb4522b0faa1050ffd20f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to outputs/checkpoint-200\n",
      "Configuration saved in outputs/checkpoint-200/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6826398372650146, 'eval_runtime': 39.8075, 'eval_samples_per_second': 15.5, 'eval_steps_per_second': 1.959, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in outputs/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-200/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from outputs/checkpoint-200 (score: 2.6826398372650146).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 754.6302, 'train_samples_per_second': 4.24, 'train_steps_per_second': 0.265, 'train_loss': 3.0358620142936705, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=3.0358620142936705, metrics={'train_runtime': 754.6302, 'train_samples_per_second': 4.24, 'train_steps_per_second': 0.265, 'train_loss': 3.0358620142936705, 'epoch': 0.05})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"short_messages\") # or model.push_to_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = \"short_messages\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(base_name)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_name)\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "inputs = tokenizer(\"Tweet text : @HondaCustSvc Your customer service has been horrible during the recall process. I will never purchase a Honda again. Label :\", return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=10)\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0])\n",
    "# 'complaint'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
