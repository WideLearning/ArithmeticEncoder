{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "conf = OmegaConf.load(\"config.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_chat_msgs(i):\n",
    "    path_to_chat, number_of_chats = conf.data.path_to_chat, conf.data.number_of_chats\n",
    "    assert i < number_of_chats, f\"i should be less than {number_of_chats}\"\n",
    "    assert i >= 0, f\"i should be greater than 0\"\n",
    "    path_to_chat = path_to_chat.format(i)\n",
    "\n",
    "    with open(path_to_chat, \"r\") as f:\n",
    "        chat = json.load(f)\n",
    "    return chat[\"messages\"]\n",
    "\n",
    "msgs = get_chat_msgs(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fields(msgs):\n",
    "    fields = [\"text\", \"from\", \"date\"]\n",
    "    msgs = [{k: msg[k] for k in fields} for msg in msgs if msg[\"type\"] == \"message\"]\n",
    "    return msgs\n",
    "\n",
    "msgs = extract_fields(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': datetime.date(2021, 12, 9), 'from': 'Rodion Khvorostov', 'text': ''},\n",
      " {'date': datetime.date(2021, 12, 9),\n",
      "  'from': 'Rodion Khvorostov',\n",
      "  'text': [{'text': 'https://stepik.org/course/%D0%9B%D0%B8%D0%BA%D0%B1%D0%B5%D0%B7-%D0%BF%D0%BE-%D0%B4%D0%B8%D1%81%D0%BA%D1%80%D0%B5%D1%82%D0%BD%D0%BE%D0%B9-%D0%BC%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B5-91',\n",
      "            'type': 'link'}]},\n",
      " {'date': datetime.date(2021, 12, 9), 'from': 'Ð›ÑŽÐ±Ð¸Ð¼Ð°Ñ ÑÐµÑÑ‚Ñ€Ñ‘Ð½ÐºÐ°ðŸ’œ', 'text': ''},\n",
      " {'date': datetime.date(2021, 12, 9), 'from': 'Ð›ÑŽÐ±Ð¸Ð¼Ð°Ñ ÑÐµÑÑ‚Ñ€Ñ‘Ð½ÐºÐ°ðŸ’œ', 'text': ''},\n",
      " {'date': datetime.date(2021, 12, 9), 'from': 'Ð›ÑŽÐ±Ð¸Ð¼Ð°Ñ ÑÐµÑÑ‚Ñ€Ñ‘Ð½ÐºÐ°ðŸ’œ', 'text': ''}]\n"
     ]
    }
   ],
   "source": [
    "# convert date to day (datetime object)\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "def convert_to_date(msgs):\n",
    "    for msg in msgs:\n",
    "        # from str 2021-09-17T22:03:43\n",
    "        msg[\"date\"] = datetime.strptime(msg[\"date\"], \"%Y-%m-%dT%H:%M:%S\").date()\n",
    "    return msgs\n",
    "\n",
    "msgs = convert_to_date(msgs)\n",
    "pprint(msgs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fix_texts(msgs):\n",
    "    for i in range(len(msgs)):\n",
    "        txt = msgs[i][\"text\"]\n",
    "        if type(txt) != str:\n",
    "            # ['ÐœÐ¾Ð¶ÐµÑ‚, ÑÑ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚))\\n\\n', {'type': 'link', 'text': 'https://contest.yandex.ru/contest/34639/problems/A/'}, '\\n\\nÐ½Ð¾ Ð±ÑƒÐ´ÑŒ Ð¾ÑÑ‚Ð¾Ñ€Ð¾Ð¶ÐµÐ½ Ñ ÑÑ‚Ð¾Ð¹ ÑÑÑ‹Ð»ÐºÐ¾Ð¹']\n",
    "            # -> 'ÐœÐ¾Ð¶ÐµÑ‚, ÑÑ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚))\\n\\n{link: https://contest.yandex.ru/contest/34639/problems/A/'}\\n\\nÐ½Ð¾ Ð±ÑƒÐ´ÑŒ Ð¾ÑÑ‚Ð¾Ñ€Ð¾Ð¶ÐµÐ½ Ñ ÑÑ‚Ð¾Ð¹ ÑÑÑ‹Ð»ÐºÐ¾Ð¹'\n",
    "            new_txt = \"\"\n",
    "            for elem in txt:\n",
    "                if type(elem) == str:\n",
    "                    new_txt += elem\n",
    "                elif type(elem) == dict:\n",
    "                    new_txt = f\"{elem['type']}: {elem['text']}\"\n",
    "            msgs[i][\"text\"] = new_txt\n",
    "    return msgs\n",
    "\n",
    "msgs = fix_texts(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 908\n",
      "After: 794\n"
     ]
    }
   ],
   "source": [
    "def remove_empty(msgs):\n",
    "    msgs = list(filter(lambda msg: msg[\"text\"] or type(msg['text']) != str, msgs))\n",
    "    return msgs\n",
    "\n",
    "# remove empty messages\n",
    "print(f\"Before: {len(msgs)}\")\n",
    "msgs = remove_empty(msgs)\n",
    "print(f\"After: {len(msgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.actors = ['me', 'you']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': datetime.date(2021, 12, 9),\n",
      "  'from': 'me',\n",
      "  'text': 'link: '\n",
      "          'https://stepik.org/course/%D0%9B%D0%B8%D0%BA%D0%B1%D0%B5%D0%B7-%D0%BF%D0%BE-%D0%B4%D0%B8%D1%81%D0%BA%D1%80%D0%B5%D1%82%D0%BD%D0%BE%D0%B9-%D0%BC%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B5-91'},\n",
      " {'date': datetime.date(2022, 2, 18), 'from': 'me', 'text': 'Ð›ÑŽÐ±, Ð¿Ñ€Ð¸Ð²ÐµÑ‚!'},\n",
      " {'date': datetime.date(2022, 2, 18), 'from': 'me', 'text': 'Ð¢Ð°Ð¼ Ð²ÑÑ‘ Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾?'},\n",
      " {'date': datetime.date(2022, 2, 18),\n",
      "  'from': 'me',\n",
      "  'text': 'Ð§Ñ‚Ð¾-Ñ‚Ð¾ Ð¼Ð°Ð¼Ð° Ð½Ðµ Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÐµÑ‚...'},\n",
      " {'date': datetime.date(2022, 2, 19), 'from': 'you', 'text': 'ÐŸÑ€Ð¸Ð²ÐµÑ‚'}]\n"
     ]
    }
   ],
   "source": [
    "# extract actor names and change them on me, friend\n",
    "\n",
    "def change_names(msgs):\n",
    "    actors_names = set([msg[\"from\"] for msg in msgs])\n",
    "    new_actors_names = conf.actors\n",
    "    actor_to_name = {actor: new_actors_names[i] for i, actor in enumerate(actors_names)}\n",
    "    msgs = [{**msg, \"from\": actor_to_name[msg[\"from\"]]} for msg in msgs]\n",
    "    return msgs\n",
    "\n",
    "msgs = change_names(msgs)\n",
    "pprint(msgs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of messages:  794\n",
      "{'date': datetime.date(2022, 7, 18), 'from': 'you', 'text': 'ÐžÐºÐµÐ¹'}\n"
     ]
    }
   ],
   "source": [
    "assert all([type(msg[\"text\"]) == str for msg in msgs]), \"Not all messages are strings\"\n",
    "assert all([bool(msg[\"text\"]) for msg in msgs]), \"Not all messages are non-empty strings\"\n",
    "# more than 10 \"link: \" messages\n",
    "assert len([msg for msg in msgs if \"link: \" in msg[\"text\"]]) > 3, \"Not enough links\"\n",
    "assert not any([msg[\"from\"] == \"Rodion Khvorostov\" for msg in msgs]), \"Rodion is here\"\n",
    "\n",
    "def pprint_rnd_elem(lst):\n",
    "    pprint(lst[np.random.randint(len(lst))])\n",
    "print(\"Number of messages: \", len(msgs))\n",
    "pprint_rnd_elem(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dialogues: 91\n"
     ]
    }
   ],
   "source": [
    "# add pair (text, from) to dialogues and actors respectively while the dialogue is during the same day\n",
    "\n",
    "def extract_dialogues(msgs):\n",
    "    dialogues, actors = [], []\n",
    "    n = len(msgs)\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        day = msgs[i][\"date\"]\n",
    "        cur_dialogue, cur_actors = [], []\n",
    "        while i < n and msgs[i][\"date\"] == day:\n",
    "            cur_dialogue.append(msgs[i][\"text\"])\n",
    "            cur_actors.append(msgs[i][\"from\"])\n",
    "            i += 1\n",
    "        dialogues.append(cur_dialogue)\n",
    "        actors.append(cur_actors)\n",
    "\n",
    "    data = {\"dialogue\": dialogues, \"actors\": actors}\n",
    "    return data\n",
    "\n",
    "data = extract_dialogues(msgs)\n",
    "n = len(data[\"dialogue\"])\n",
    "print(f\"Number of dialogues: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random dialogue number: 30\n",
      "['ÐŸÑ€Ð¸Ð²ÐµÑ‚)',\n",
      " 'ÐšÐ°Ðº Ð´ÐµÐ»Ð°?',\n",
      " 'ÐŸÑ€Ð¸Ð²ÐµÑ‚. ÐŸÐ¾-Ñ‚Ð¸Ñ…Ð¾Ð½ÑŒÐºÑƒ Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ñ€ÑƒÑŽÑÑŒ:)\\nÐ£ Ñ‚ÐµÐ±Ñ ÐºÐ°Ðº? ÐÐ°Ñ‡Ð°Ð»Ð°ÑÑŒ ÑƒÑ‡Ñ‘Ð±Ð°?',\n",
      " 'Ð¡ÐµÐ³Ð¾Ð´Ð½Ñ Ð±Ñ‹Ð»Ð¾ ÑÐ¾Ð±Ñ€Ð°Ð½Ð¸Ðµ',\n",
      " 'Ð ÑƒÑ‡Ã«Ð±Ð° Ð·Ð°Ð²Ñ‚Ñ€Ð° Ð½Ð°Ñ‡Ð½Ã«Ñ‚ÑÑ',\n",
      " 'ÐÐ¾ Ð¿Ð¾ÐºÐ° Ð½Ðµ Ð¿Ð¾Ð½ÑÑ‚Ð½Ð¾',\n",
      " 'Ð£ Ð½Ð°Ñ Ð·Ð°Ð²Ñ‚Ñ€Ð° Ñ€Ð¸ÑÑƒÐ½Ð¾Ðº 8 Ñ‡Ð°ÑÐ¾Ð²',\n",
      " 'ÐÐµ Ð¿Ð¾Ð½ÑÑ‚Ð½Ð¾, Ñ‡Ñ‚Ð¾ Ð±ÑƒÐ´ÐµÐ¼ Ð´ÐµÐ»Ð°Ñ‚ÑŒ',\n",
      " 'ÐÑƒ Ð½Ð¸Ñ‡ÐµÐ³Ð¾, Ð¶ÐµÐ»Ð°ÑŽ ÑƒÐ´Ð°Ñ‡Ð¸!',\n",
      " 'Ð¡Ð¿Ð°ÑÐ¸Ð±Ð¾) ðŸ’–',\n",
      " 'Ð¡ÐºÐ¸Ð½ÑŒ Ð½Ð¾Ð¼ÐµÑ€ Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½Ð° Ð”ÑÐ´Ð¸ Ð¿Ð¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°',\n",
      " 'Ð¡Ð¿Ð°ÑÐ¸Ð±Ð¾']\n",
      "Actors: ['you', 'you', 'me', 'you', 'you', 'you', 'you', 'you', 'me', 'you', 'you', 'you']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "rnd = np.random.randint(n)\n",
    "print(f\"Random dialogue number: {rnd}\")\n",
    "pprint(data['dialogue'][rnd])\n",
    "print(f\"Actors: {data['actors'][rnd]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_process(i):\n",
    "    msgs = get_chat_msgs(i)\n",
    "    msgs = extract_fields(msgs)\n",
    "    msgs = convert_to_date(msgs)\n",
    "    msgs = fix_texts(msgs)\n",
    "    msgs = remove_empty(msgs)\n",
    "    msgs = change_names(msgs)\n",
    "    data = extract_dialogues(msgs)\n",
    "    return data\n",
    "\n",
    "def process_all():\n",
    "    number_of_chats = conf.data.number_of_chats\n",
    "    data = {\n",
    "        \"dialogue\": [],\n",
    "        \"actors\": []\n",
    "    }\n",
    "    for i in range(number_of_chats):\n",
    "        data_local = full_process(i)\n",
    "        data[\"dialogue\"].extend(data_local[\"dialogue\"])\n",
    "        data[\"actors\"].extend(data_local[\"actors\"])\n",
    "    return data\n",
    "\n",
    "data = process_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user010/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['dialogue', 'actors'],\n",
       "    num_rows: 1187\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "token = os.environ[\"HUGGING_FACE_HUB_TOKEN\"]\n",
    "assert token, \"No token found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/user010/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login, login\n",
    "\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39670a443e284776b90c026b1cd881c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b57affa9b74f1aa12bd7ef0e056004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba1ad95d98941c7a9f6bef1ef1ad20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.push_to_hub(conf.data.dataset_name, private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
